\chapter{Methodology}
\label{cha:Methodology}

The project will be divided in five main phases:
\begin{itemize}
    \item Litterature search
    \item Preprocessing of datasets
    \item Statistical analysis of datasets
    \item Combining the datasets
    \item Machine learning on datasets
\end{itemize}
whereas the litterature search was described in \autoref{sec:literature_review}, and the other parts will be described in this chapter.

\section{Techincal setup}
In \autoref{tab:software}, the main software used in this project is listed.

\begin{table}[ht]
    \centering
    \begin{tabular}{|c|c|c|}
       \hline
       Software & Version & Usage \\
       \hline 
       Python\tablefootnote{\url{https://www.python.org}} & 3.9.7 & Programming language \\
       \hline
       NumPy\tablefootnote{\url{https://numpy.org}} & 1.20.3 & Numerical calculations with vectors and matrices \\
       \hline
       scikit-learn\tablefootnote{\url{https://scikit-learn.org/}} & 0.24.2 & Machine learning \\
       \hline
       XGBoost\tablefootnote{\url{https://xgboost.readthedocs.io/}} & 1.4.2 & XGBoost machine learning algorithm \\
       \hline
    \end{tabular}
    \caption{Software used in this project}
    \label{tab:software}
\end{table}

\section{Preprocessing of the datasets}
Preprocessing is done to each of the datasets in order to make the datasets as comparable as possible.

\subsection{Log-transforming the data}
The log-transformation is explained closer in \autoref{subsec:var_stab}. The point of this is that we see that the variance in miRNA levels are approximately proportional to the square of the mean of the miRNA levels. Then log-transformation will make the variance independent from the mean constant.

\subsection{Loess regression on the mean-variance relationship}
In some cases, especially if the study uses microarrays, the mean-variance relationship is still not constant after log-transforming the data. In this case, loess regression (see: \autoref{subsec:loess_regression}) is used to adjust the variance of the samples to ensure that the variance is independent of the mean. An example is in \autoref{fig:loess}.

\begin{figure}
    \begin{subfigure}[b]{0.5\textwidth}
    \resizebox{\textwidth}{!}{
    \begin{tikzpicture}
    \begin{axis}[
        xlabel={Mean miRNA concentration},
        ylabel={Variance of miRNA concentration},
    ]
    \addplot[
        scatter,only marks,scatter src=explicit symbolic,
        table/col sep=comma,
        scatter/classes={
	    Sample points={blue},
	    Loess regression={yellow}
	}
    ]
    table[x=means,y=variances,meta=type]{tables/Loess/Before.csv};
    \legend{Sample points, Loess regression}
    \end{axis}
    \end{tikzpicture}
    }
    \caption{Mean and variance before loess adjustment}
    \label{fig:loess_before}
    \end{subfigure}
    \begin{subfigure}[b]{0.5\textwidth}
    \resizebox{\textwidth}{!}{
    \begin{tikzpicture}
    \begin{axis}[
        xlabel={Mean miRNA concentration},
        ylabel={Variance of miRNA concentration},
    ]
    \addplot[
        scatter,only marks,scatter src=x,
        table/col sep=comma,
	scatter/use mapped color={draw=blue, fill=blue}
    ]
    table[x=means,y=variances]{tables/Loess/After.csv};
    \end{axis}
    \end{tikzpicture}
    }
    \caption{Mean and variance after loess adjustment}
    \label{fig:loess_before}
    \end{subfigure}
    \caption{Mean and variance before and after loess in \citet{Asakura2020}}
    \label{fig:loess}
\end{figure}



\subsection{Adjusting for covariates}
Some datasets report information about the patients, including their sex, age and/or pack years\footnote{pack years = packs of cigaretts smoked per day * number of years smoked}. These demographic variables affect the miRNA levels, and we want to make these variables have as little influence as possible on the miRNA levels. Therefore, a linear regression model is fitted with the demographic variables as covariates, and with the miRNA levels as dependent variables. The resulting model will then have an estimate of the effect of the different covariates. By subtracting the effect of these covariates, more of the variance in the miRNA levels will be due to case-control characteristics. Another advantage of doing this adjustment is that the demographics of the different studies will differ, and by removing the effect of demographic variables, the studies become more comparable.


\subsection{Standardizing miRNA levels}
In order to make the measured miRNA levels comparable when they are measured using different technologies, the measured miRNA levels for each miRNA-sequence are standardized. However, one has to take into account that the datasets differ in the relative number of cancer and control samples. To adjust for this, mean and empirical variance was calculated for the cancer and the control samples seperately. Let $\hat{\mu}_{ca}$ and $\hat{\sigma}_{ca}^2$ be the mean and emirical variance of the cancer samples, and likewise $\hat{\mu}_{co}$ and $\hat{\sigma}_{co}^2$ for the controls. Then the overall mean $\hat{\mu}$ and overall variance $\hat{\sigma}^2$ is estimated as:

\begin{align*}
	\hat{\mu} & = \frac{\hat{\mu}_{ca} + \hat{\mu}_{co}}{2} \\
	\hat{\sigma}^2 &= \frac{\hat{\sigma}_{ca}^2 + \hat{\sigma}_{co}^2}{2}
\end{align*}

which is the expected mean and variance if the dataset were balanced with an equal number of cancer and control samples.

\section{Statistical analysis of the datasets}
To get an overview of the datasets, different statistical analysis are done on the datasets.

\subsection{Explained variance}
An interesting question is how much of the variance in the miRNA levels is due to case-control in the different datasets. It is plausible that datasets that have only measured miRNA-sequences assumed to have a correlation with lung cancer, have a larger portion of the variance due to case-control. As explained variance is made for the case where there is only one dependent variable, one has to do some adjustments to get an overall estimate. One way is to take the average of the explained variance for each miRNA-sequence. Another way will be to to weight by the variance of each miRNA-sequence, as miRNA-sequences showing more variance might do so due to case-control effects. I will calculate both statistics. The explained variance will be calculated after the log-transformation, to be sure that the distribution of the levels for each miRNA-sequence is approximately normally distributed, as this is one of the prerequisites for the explained variance-analysis to be valid.

Explained variance will be calculated using \verb|LinearRegression| and \\ \verb|explained_variance_score| in scikit-learn.

\subsection{PCA}
I want to run PCA, with two principal components, on the different datasets, as it makes it possible to visualize the dataset in a plot. This serves multiple purposes; first of all it makes it possible to find outliers in the datasets, as they would be far from the other samples in the plot. Secondly, by coloring the samples by whether they are cases or controls, one can visualize how separable the data are between cases and controls. This last point assumes that case-control effects on the data are along one (or both) of the first two principal components, as if they are not, the plot would not be separable, even though the full dataset might be. As the first components represent the main sources of variance in the data, seeing whether the data is separable in case-control in the plot is an alternative to ANOVA, for seeing whether case-control effects are the main causes of variance in the dataset.

PCA will be computed by the \verb|PCA| function in scikit-learn.

\subsection{Fold change correlation}
Another interesting question is whether the fold changes between cases and controls are the same in the different datasets. To do that, I will calculate the fold changes between the case and control in the different datasets, for different miRNA-sequences. There should be some correlation between fold changes in the different datasets, otherwise, it would seem that the biomarkers for lung cancer in the different datasets cannot be replicated, and thus one might question the results of the studies. 


\section{Combining datasets}
Combining the datasets are done by using the processed datasets and 


\section{Machine learning on datasets}




\iffalse
Here you will present the architecture or model that you have chosen and that is (or will be) implemented in your work. Note that putting algorithms in your report is not desirable but in certain cases these might be placed in the appendix. Code further be avoided in the report itself but may be delivered in the fashion requested by the supervisor or, in the case of masters delivery, submitted as additional documents. 
\fi
